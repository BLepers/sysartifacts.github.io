<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- Based on a template from Thomas Wenisch. Photo from https://www.flickr.com/photos/voteprime/8320401346 -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Research Artifact Evaluation @ SOSP 2019</title>
<link rel="stylesheet" type="text/css" href="./index_files/css-buttons.css">
<link rel="stylesheet" type="text/css" href="./index_files/course.css">
</head>
<body>
<div id="abstract_box">x</div>
<div id="banner" style="background-image: url(images/rube-goldberg.jpg)"></div>
<div id="header">
  <div id="details">
     <h1>Research Artifact Evaluation @ SOSP 2019</h1>
    <table class="alist">
       	<tbody>
        	<tr><th>Submission site</th><td><a href="https://sosp19ae.hotcrp.com/">
			https://sosp19ae.hotcrp.com/</a></td></tr>
        	<tr><th>Submission deadline</th><td>August 7, 2019 AoE (for Artifact Available badge)
			<br>August 14, 2019 AoE (for Artifact Functional/Results Replicated badges)</td></tr>
        	<tr><th>Technical Chairs</th><td>Baris Kasikci, University of Michigan
			<br>Vijay Chidambaram, University of Texas at Austin</td></tr>
        	<tr><th>Organizing Chair</th><td>Supreeth Shastri, University of Texas at Austin</td></tr>
        </tbody></table>
  </div>
</div>

<hr style="height:0px">
<ul id="nav">
<li><a id="home" class="good" href="index.html">Home</a></li>
<li><a id="goals" class="good" href="goals.html">Goals</a></li>
<li><a id="organizers" class="good" href="organizers.html">Organizers</a></li>
<li><a id="badging" class="good" href="badges.html">ACM Badges</a></li>
<li><a id="instructions" class="good" href="instructions.html">Instructions</a></li>
<li><a id="Results" class="good" href="results.html">Results</a></li>
<li><a id="Report" class="good" href="report.html">Final Report</a></li>
</ul>

<div id="content">

<h1>Report from the chairs</h1>

<p>We are happy to report the conclusion of the artifact evaluation (AE) process for papers accepted at SOSP 2019. Here, we share our experiences in organizing the first such effort at SOSP, and ruminate on key takeaways. Our hope is that this effort serves as a catalyst in making artifact evaluation more common at systems conferences.</p> 

<h2>Summary</h2>
<p><b>Preamble</b>: As this was the inaugural year, AE was voluntary for all the accepted papers. However, we were encouraged to see that 23 of the 38 (= 61%) applied to go through the evaluation. Next, to form the artifact evaluation committee (AEC), we reached out to the broader systems community via Twitter and Slack (systems-research). This helped us bring together a <a href="organizers.html">team</a> of 42 early-career researchers and graduate students, who volunteered to read the papers and undertake the evaluation. Finally, in terms of artifact badges to be awarded, we gleaned over recommendations from the ACM and the PL community, and decided on <a href="badges.html">three badges</a> that made sense for systems research: <em>Artifact Available</em>, which requires the artifact to be made available for retrieval, publicly and permanently; <em>Artifact Functional</em>, which ensures that the artifact has gone through an independent audit, and it functions as described; and finally <em>Results Replicated</em>, which confirms that the main results of the paper could be obtained independently using the supplied artifacts.</p>

<p><b>Evaluation</b>: We designed the evaluation process to be single-blind (i.e., identity of the evaluators was not revealed to the authors). Every artifact was evaluated by at least two members of the AEC. Unlike the paper review process, we advised the AEC members to work with the authors to help them achieve the badges they sought. This required a significant amount of communication between the evaluators and authors as well as accepting several revisions of artifacts and instructions. Due to the single-blind nature of the process, all communications were via HotCRP comments. Average length of communications including reviews and comments was 3456 words per paper. The whole process starting from authors registering their artifacts, to evaluators familiarizing themselves with the underlying research papers, to verifying the artifact functionality, to reproducing the results, to writing the reviews, and to awarding the badges was completed in the span of 28 days.</p> 

<p><b>Badges</b>: Of the submitted papers, 22 (96%) earned at least one badge, and 11 (48%) earned all three badges. The authors expressed strong preferences for open-sourcing their artifacts, and to our surprise, nearly 40% of the <em>Artifact Available</em> badges were awarded to papers from industry or those that had industrial collaborators. Finally, despite having to meet rigorous standards in a short evaluation timeframe, 19 artifacts earned the <em>Artifact Functional</em> badge, and 12 earned the <em>Results Replicated</em> badge. We have tabulated detailed results along with links to artifacts <a href="results.html">here</a>.</p> 

<h2>Key Takeaways</h2>

<p>1. <b>AE made the papers better.</b> This manifested at two levels. The requirements of the badges meant that the artifacts are not only publicly available but also verified to be functional and usable. So, for the first time, a number of SOSP papers will release artifacts that have been externally validated. The second aspect is about the accuracy of results. For instance, when AEC members identified a performance mismatch, the authors worked with them to root cause it to usage of older versions of external dependencies (TensorFlow). In response, the authors revised the numbers in their camera ready paper.</p>

<p>2. <b>Specialized hardware is not a hindrance for AE.</b> Our effort dispels the conventional wisdom that projects involving custom hardware or expansive clusters cannot be evaluated. We observed that in such cases, the authors allowed AEC members to access their resources (via ssh) to perform evaluations. This was the case for 6 (out of 23) evaluations.</p>

<p>3. <b>Interest in AE is not limited to academic projects.</b> Nearly 40% of the submitted artifacts either originated from industry, or had industrial collaborators. Half the industry papers got all three badges. Even when business concerns did not allow open-sourcing the artifacts, the authors were happy to let AEC members access artifacts privately.</p>

<p>4. <b>AE should be alloted ample time and resources.</b> This SOSP AE was conceived after the paper submission deadline had passed. As a result, we had to make it voluntary, and limit its applicability to only accepted papers. We anticipate that integrating the call for AE with the call for papers should allow much broader participation. Also, allocating dedicated hardware resources (or cloud credits) would free AEC members from the burdens of scouting for resources on their own.</p> 

<br><br><br>
</body></html>
